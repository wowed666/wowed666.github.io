---
layout: post
title: Blog Post 2 Spectral Clustering
---



In this post I will be guiding you through the process of creating a simple spectral clustering algorithm.
Spectral clustering allows us to find similarities in data points.
In this simple tutorial, we will understand how to partition data into their natural clusters.


## Introduction

In this part we'll study *spectral clustering*. Spectral clustering is an important tool for identifying meaningful
parts of data sets with complex structure. To start, let's look at an example where we *don't* need spectral clustering. 

 
Firstly let's import the package that we'll need!

```python


import numpy as np
from sklearn import datasets
from matplotlib import pyplot as plt


```

```python
n = 200
np.random.seed(1111)
X, y = datasets.make_blobs(n_samples=n, shuffle=True, random_state=None, centers = 2, cluster_std = 2.0)
plt.scatter(X[:,0], X[:,1])


```
![HW2_1.png](/images/Blog2/HW2_1.png)

```python
from sklearn.cluster import KMeans
km = KMeans(n_clusters = 2)
km.fit(X)

plt.scatter(X[:,0], X[:,1], c = km.predict(X))
```
![HW2_2.png](/images/Blog2/HW2_2.png)

## Harder Clustering
That was all well and good, but what if our data is "shaped weird"?

```python
np.random.seed(1234)
n = 200
X, y = datasets.make_moons(n_samples=n, shuffle=True, noise=0.05, random_state=None)
plt.scatter(X[:,0], X[:,1])
```
![HW2_3.png](/images/Blog2/HW2_3.png)
We can still make out two meaningful clusters in the data, but now they aren't blobs but crescents. 
As before, the Euclidean coordinates of the data points are contained in the matrix X, while the labels of each point are contained in y. 
Now k-means won't work so well, because k-means is, by design, looking for circular clusters.

```python
km = KMeans(n_clusters = 2)
km.fit(X)
plt.scatter(X[:,0], X[:,1], c = km.predict(X))

```
![HW2_4.png](/images/Blog2/HW2_4.png)

Whoops! That's not right!

As we'll see, spectral clustering is able to correctly cluster the two crescents. In the following problems, you will derive and implement spectral clustering.

## Part A
First, we begin by creating a similariy matrix of shape (n,n) that contains the distances between each pair of coordinates in the matrix.

We can import 'pairwise_distances' from sklearn.metrics' to get the distances between each pair of coordinates in the matrix.

When constructing the similarity matrix, use a parameter epsilon. Entry A[i,j] should be equal to 1 if X[i] (the coordinates of data point i) is within distance epsilon of X[j] (the coordinates of data point j).

The diagonal entries A[i,i] should all be equal to zero.

```python
from sklearn.metrics import pairwise_distances 

epsilon = 0.4

def similarity_matrix(X,epsilon)

    n = len(X)
    # If distance if X[i] is within distance epsilon of X[j] then A[i,j] be "1",
    # else A[i,j] be "0"
    A = (pairwise_distances(X) < epsilon * np.ones((n,n)))*1

    # The diagonal entries A[i,i] should all be equal to zero. 
    np.fill_diagonal(A,0)
    
    return A

similarity_matrix(X,epsilon)
```
<div class="output_subarea output_text output_result" dir="auto"><pre>array([[0, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 1, 0],
       ...,
       [0, 0, 0, ..., 0, 1, 1],
       [0, 0, 1, ..., 1, 0, 1],
       [0, 0, 0, ..., 1, 1, 0]])</pre></div>

{::options parse_block_html="true" /}
<div class="got-help">
My peer suggest me define a function of similarity_matrix then I could use this function for Part G
</div>
{::options parse_block_html="false" /}

{::options parse_block_html="true" /}
<div class="gave-help">
I gave give my peers a suggestion about use "*1" to change the boolean type value to integer type
</div>
{::options parse_block_html="false" /}

## PartB
Let's write a function called `cut(A,y)` to compute the cut term. You can compute it by summing up the entries `A[i,j]` for each pair of points `(i,j)` in different clusters. 
```python

def cut(A, y):
    # initiate cut sum 
    cut_sum = 0
    
    #np.where(y == 0)[0] get the an array of index position of value in "y" equal "0" which is C0
    #np.where(y == 1)[0] get the an array of index position of value in "y" equal "1" which is C1
    for i in np.where(y == 0)[0]:
        for j in np.where(y == 1)[0]:
            cut_sum += A[i,j]
    # returns cut sum
    return cut_sum    

```
Compute the cut objective for the true clusters y. Then, generate a random vector of random labels of length n, with each label equal to either 0 or 1. Check the cut objective for the random labels. You should find that the cut objective for the true labels is much smaller than the cut objective for the random labels.

This shows that this part of the cut objective indeed favors the true clusters over the random ones.
```python

temp = np.random.randint(2,size = n)
true = cut(A,y)
rand = cut(A,temp)
(true,rand)
```
(13, 1125)


#### B.2 The Volume Term 
Let's define a function "vols": It take a similarity matrix and The cluster membership as being specified by y
It give volum of C0 and C1

Then, write a function called `normcut(A,y)` which uses `cut(A,y)` and `vols(A,y)` to compute the binary normalized cut objective of a matrix `A` with clustering vector `y`. 

```python

def vols(A,y):
    v0 = A[y == 0].sum() # row sum for which y == 0
    v1 = A.sum() - v0  # row sum for which y == 1
    return(v0,v1)

def normcut(A,y):
    (v0,v1) = vols(A,y)
    c = cut(A,y)
    return(c*(1/v0+1/v1))

```
Now, compare the normcut objective using both the true labels y and the fake labels you generated above

```python
(normcut(A,y),normcut(A,temp))

```
(0.011518412331615225, 0.995836336735081)

Compare to true claster  we get a very low value for the binary norm cut objective.


## Part C

We have now defined a normalized cut objective which takes small values when the input clusters are (a) joined by relatively few entries in $A$ and (b) not too small. One approach to clustering is to try to find a cluster vector `y` such that `normcut(A,y)` is small. However, this is an NP-hard combinatorial optimization problem, which means that may not be possible to find the best clustering in practical time, even for relatively small data sets. We need a math trick! 

Here's the trick: define a new vector $\mathbf{z} \in \mathbb{R}^n$ such that: 

$$
z_i = 
\begin{cases}
    \frac{1}{\mathbf{vol}(C_0)} &\quad \text{if } y_i = 0 \\ 
    -\frac{1}{\mathbf{vol}(C_1)} &\quad \text{if } y_i = 1 \\ 
\end{cases}
$$


Note that the signs of  the elements of $\mathbf{z}$ contain all the information from $\mathbf{y}$: if $i$ is in cluster $C_0$, then $y_i = 0$ and $z_i > 0$. 

Next, if you like linear algebra, you can show that 

$$\mathbf{N}_{\mathbf{A}}(C_0, C_1) = 2\frac{\mathbf{z}^T (\mathbf{D} - \mathbf{A})\mathbf{z}}{\mathbf{z}^T\mathbf{D}\mathbf{z}}\;,$$

where $$\mathbf{D}$$ is the diagonal matrix with nonzero entries $d_{ii} = d_i$, and  where $d_i = \sum_{j = 1}^n a_i$ is the degree (row-sum) from before.  

```python

def transform(A,y):
    v0,v1 = vols(A,y)
    z = 1/v0*(y == 0)-1/v1*(y == 1)
    return(z)
    z = transform(A,y)
    # compute the row sum
    v = A.sum(axis = 1)
    # row sum as the diagonal entries
    D = np.diag(v)
    np.isclose(normcut(A,y),z.T@(D-A)@z/(z.T@D@z))
```
```
True
```

```python
np.isclose(0,z.T@D@np.ones(n))
```
```
True
```

<div class="text_cell_render rendered_html" tabindex="-1" dir="ltr"><h2 id="Part-D">Part D<a class="anchor-link" href="#Part-D">¶</a></h2>
<p>In the last part, we saw that the problem of minimizing the normcut objective is mathematically related to the problem of minimizing the function </p>
<p><span class="MathJax_Preview" style="color: inherit;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-106-Frame" tabindex="0" style="text-align: center; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>R</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;bold&quot;>A</mi></mrow></msub><mo stretchy=&quot;false&quot;>(</mo><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;bold&quot;>z</mi></mrow><mo stretchy=&quot;false&quot;>)</mo><mo>&amp;#x2261;</mo><mfrac><mrow><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;bold&quot;>z</mi></mrow><mi>T</mi></msup><mo stretchy=&quot;false&quot;>(</mo><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;bold&quot;>D</mi></mrow><mo>&amp;#x2212;</mo><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;bold&quot;>A</mi></mrow><mo stretchy=&quot;false&quot;>)</mo><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;bold&quot;>z</mi></mrow></mrow><mrow><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;bold&quot;>z</mi></mrow><mi>T</mi></msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;bold&quot;>D</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;bold&quot;>z</mi></mrow></mrow></mfrac></math>" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1201" style="width: 10.598em; display: inline-block;"><span style="display: inline-block; position: relative; width: 8.813em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(0.955em, 1008.81em, 3.515em, -999.997em); top: -2.616em; left: 0em;"><span class="mrow" id="MathJax-Span-1202"><span class="msubsup" id="MathJax-Span-1203"><span style="display: inline-block; position: relative; width: 1.313em; height: 0px;"><span style="position: absolute; clip: rect(3.158em, 1000.72em, 4.17em, -999.997em); top: -3.985em; left: 0em;"><span class="mi" id="MathJax-Span-1204" style="font-family: STIXMathJax_Normal-italic;">𝑅</span><span style="display: inline-block; width: 0px; height: 3.991em;"></span></span><span style="position: absolute; top: -3.807em; left: 0.717em;"><span class="texatom" id="MathJax-Span-1205"><span class="mrow" id="MathJax-Span-1206"><span class="mi" id="MathJax-Span-1207" style="font-size: 70.7%; font-family: STIXMathJax_Normal-bold;">𝐀</span></span></span><span style="display: inline-block; width: 0px; height: 3.991em;"></span></span></span></span><span class="mo" id="MathJax-Span-1208" style="font-family: STIXMathJax_Main;">(</span><span class="texatom" id="MathJax-Span-1209"><span class="mrow" id="MathJax-Span-1210"><span class="mi" id="MathJax-Span-1211" style="font-family: STIXMathJax_Normal-bold;">𝐳</span></span></span><span class="mo" id="MathJax-Span-1212" style="font-family: STIXMathJax_Main;">)</span><span class="mo" id="MathJax-Span-1213" style="font-family: STIXMathJax_Main; padding-left: 0.301em;">≡</span><span class="mfrac" id="MathJax-Span-1214" style="padding-left: 0.301em;"><span style="display: inline-block; position: relative; width: 4.824em; height: 0px; margin-right: 0.122em; margin-left: 0.122em;"><span style="position: absolute; clip: rect(2.979em, 1004.71em, 4.348em, -999.997em); top: -4.64em; left: 50%; margin-left: -2.378em;"><span class="mrow" id="MathJax-Span-1215"><span class="msubsup" id="MathJax-Span-1216"><span style="display: inline-block; position: relative; width: 1.015em; height: 0px;"><span style="position: absolute; clip: rect(3.336em, 1000.42em, 4.17em, -999.997em); top: -3.985em; left: 0em;"><span class="texatom" id="MathJax-Span-1217"><span class="mrow" id="MathJax-Span-1218"><span class="mi" id="MathJax-Span-1219" style="font-family: STIXMathJax_Normal-bold;">𝐳</span></span></span><span style="display: inline-block; width: 0px; height: 3.991em;"></span></span><span style="position: absolute; top: -4.342em; left: 0.42em;"><span class="mi" id="MathJax-Span-1220" style="font-size: 70.7%; font-family: STIXMathJax_Normal-italic;">𝑇<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.063em;"></span></span><span style="display: inline-block; width: 0px; height: 3.991em;"></span></span></span></span><span class="mo" id="MathJax-Span-1221" style="font-family: STIXMathJax_Main;">(</span><span class="texatom" id="MathJax-Span-1222"><span class="mrow" id="MathJax-Span-1223"><span class="mi" id="MathJax-Span-1224" style="font-family: STIXMathJax_Normal-bold;">𝐃</span></span></span><span class="mo" id="MathJax-Span-1225" style="font-family: STIXMathJax_Main; padding-left: 0.241em;">−</span><span class="texatom" id="MathJax-Span-1226" style="padding-left: 0.241em;"><span class="mrow" id="MathJax-Span-1227"><span class="mi" id="MathJax-Span-1228" style="font-family: STIXMathJax_Normal-bold;">𝐀</span></span></span><span class="mo" id="MathJax-Span-1229" style="font-family: STIXMathJax_Main;">)</span><span class="texatom" id="MathJax-Span-1230"><span class="mrow" id="MathJax-Span-1231"><span class="mi" id="MathJax-Span-1232" style="font-family: STIXMathJax_Normal-bold;">𝐳</span></span></span></span><span style="display: inline-block; width: 0px; height: 3.991em;"></span></span><span style="position: absolute; clip: rect(3.039em, 1002.15em, 4.17em, -999.997em); top: -3.271em; left: 50%; margin-left: -1.068em;"><span class="mrow" id="MathJax-Span-1233"><span class="msubsup" id="MathJax-Span-1234"><span style="display: inline-block; position: relative; width: 1.015em; height: 0px;"><span style="position: absolute; clip: rect(3.336em, 1000.42em, 4.17em, -999.997em); top: -3.985em; left: 0em;"><span class="texatom" id="MathJax-Span-1235"><span class="mrow" id="MathJax-Span-1236"><span class="mi" id="MathJax-Span-1237" style="font-family: STIXMathJax_Normal-bold;">𝐳</span></span></span><span style="display: inline-block; width: 0px; height: 3.991em;"></span></span><span style="position: absolute; top: -4.283em; left: 0.42em;"><span class="mi" id="MathJax-Span-1238" style="font-size: 70.7%; font-family: STIXMathJax_Normal-italic;">𝑇<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.063em;"></span></span><span style="display: inline-block; width: 0px; height: 3.991em;"></span></span></span></span><span class="texatom" id="MathJax-Span-1239"><span class="mrow" id="MathJax-Span-1240"><span class="mi" id="MathJax-Span-1241" style="font-family: STIXMathJax_Normal-bold;">𝐃</span></span></span><span class="texatom" id="MathJax-Span-1242"><span class="mrow" id="MathJax-Span-1243"><span class="mi" id="MathJax-Span-1244" style="font-family: STIXMathJax_Normal-bold;">𝐳</span></span></span></span><span style="display: inline-block; width: 0px; height: 3.991em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1004.82em, 1.253em, -999.997em); top: -1.307em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 4.824em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.074em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.622em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.925em; border-left: 0px solid; width: 0px; height: 2.861em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msub><mi>R</mi><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">A</mi></mrow></msub><mo stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">z</mi></mrow><mo stretchy="false">)</mo><mo>≡</mo><mfrac><mrow><msup><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">z</mi></mrow><mi>T</mi></msup><mo stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">D</mi></mrow><mo>−</mo><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">A</mi></mrow><mo stretchy="false">)</mo><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">z</mi></mrow></mrow><mrow><msup><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">z</mi></mrow><mi>T</mi></msup><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">D</mi></mrow><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">z</mi></mrow></mrow></mfrac></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-106"> R_\mathbf{A}(\mathbf{z})\equiv \frac{\mathbf{z}^T (\mathbf{D} - \mathbf{A})\mathbf{z}}{\mathbf{z}^T\mathbf{D}\mathbf{z}} </script></p>
<p>subject to the condition <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-107-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;bold&quot;>z</mi></mrow><mi>T</mi></msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;bold&quot;>D</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn mathvariant=&quot;double-struck&quot;>1</mn></mrow><mo>=</mo><mn>0</mn></math>" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1245" style="width: 4.884em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.051em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.61em, 1004.05em, 2.801em, -999.997em); top: -2.616em; left: 0em;"><span class="mrow" id="MathJax-Span-1246"><span class="msubsup" id="MathJax-Span-1247"><span style="display: inline-block; position: relative; width: 1.015em; height: 0px;"><span style="position: absolute; clip: rect(3.336em, 1000.42em, 4.17em, -999.997em); top: -3.985em; left: 0em;"><span class="texatom" id="MathJax-Span-1248"><span class="mrow" id="MathJax-Span-1249"><span class="mi" id="MathJax-Span-1250" style="font-family: STIXMathJax_Normal-bold;">𝐳</span></span></span><span style="display: inline-block; width: 0px; height: 3.991em;"></span></span><span style="position: absolute; top: -4.342em; left: 0.42em;"><span class="mi" id="MathJax-Span-1251" style="font-size: 70.7%; font-family: STIXMathJax_Normal-italic;">𝑇<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.063em;"></span></span><span style="display: inline-block; width: 0px; height: 3.991em;"></span></span></span></span><span class="texatom" id="MathJax-Span-1252"><span class="mrow" id="MathJax-Span-1253"><span class="mi" id="MathJax-Span-1254" style="font-family: STIXMathJax_Normal-bold;">𝐃</span></span></span><span class="texatom" id="MathJax-Span-1255"><span class="mrow" id="MathJax-Span-1256"><span class="mn" id="MathJax-Span-1257" style="font-family: STIXMathJax_DoubleStruck;">𝟙</span></span></span><span class="mo" id="MathJax-Span-1258" style="font-family: STIXMathJax_Main; padding-left: 0.301em;">=</span><span class="mn" id="MathJax-Span-1259" style="font-family: STIXMathJax_Main; padding-left: 0.301em;">0</span></span><span style="display: inline-block; width: 0px; height: 2.622em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.068em; border-left: 0px solid; width: 0px; height: 1.146em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">z</mi></mrow><mi>T</mi></msup><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">D</mi></mrow><mrow class="MJX-TeXAtom-ORD"><mn mathvariant="double-struck">1</mn></mrow><mo>=</mo><mn>0</mn></math></span></span><script type="math/tex" id="MathJax-Element-107">\mathbf{z}^T\mathbf{D}\mathbb{1} = 0</script>. It's actually possible to bake this condition into the optimization, by substituting for <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-108-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;bold&quot;>z</mi></mrow></math>" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1260" style="width: 0.539em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.42em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.967em, 1000.42em, 2.801em, -999.997em); top: -2.616em; left: 0em;"><span class="mrow" id="MathJax-Span-1261"><span class="texatom" id="MathJax-Span-1262"><span class="mrow" id="MathJax-Span-1263"><span class="mi" id="MathJax-Span-1264" style="font-family: STIXMathJax_Normal-bold;">𝐳</span></span></span></span><span style="display: inline-block; width: 0px; height: 2.622em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.068em; border-left: 0px solid; width: 0px; height: 0.718em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">z</mi></mrow></math></span></span><script type="math/tex" id="MathJax-Element-108">\mathbf{z}</script> the orthogonal complement of <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-109-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;bold&quot;>z</mi></mrow></math>" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1265" style="width: 0.539em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.42em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.967em, 1000.42em, 2.801em, -999.997em); top: -2.616em; left: 0em;"><span class="mrow" id="MathJax-Span-1266"><span class="texatom" id="MathJax-Span-1267"><span class="mrow" id="MathJax-Span-1268"><span class="mi" id="MathJax-Span-1269" style="font-family: STIXMathJax_Normal-bold;">𝐳</span></span></span></span><span style="display: inline-block; width: 0px; height: 2.622em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.068em; border-left: 0px solid; width: 0px; height: 0.718em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">z</mi></mrow></math></span></span><script type="math/tex" id="MathJax-Element-109">\mathbf{z}</script> relative to <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-110-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;bold&quot;>D</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn mathvariant=&quot;bold&quot;>1</mn></mrow></math>" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1270" style="width: 1.551em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.253em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.729em, 1001.19em, 2.801em, -999.997em); top: -2.616em; left: 0em;"><span class="mrow" id="MathJax-Span-1271"><span class="texatom" id="MathJax-Span-1272"><span class="mrow" id="MathJax-Span-1273"><span class="mi" id="MathJax-Span-1274" style="font-family: STIXMathJax_Normal-bold;">𝐃</span></span></span><span class="texatom" id="MathJax-Span-1275"><span class="mrow" id="MathJax-Span-1276"><span class="mn" id="MathJax-Span-1277" style="font-family: STIXMathJax_Main-bold;">1</span></span></span></span><span style="display: inline-block; width: 0px; height: 2.622em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.068em; border-left: 0px solid; width: 0px; height: 1.004em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">D</mi></mrow><mrow class="MJX-TeXAtom-ORD"><mn mathvariant="bold">1</mn></mrow></math></span></span><script type="math/tex" id="MathJax-Element-110">\mathbf{D}\mathbf{1}</script>. In the code below, I define an <code>orth_obj</code> function which handles this for you. </p>
</div>

```python
def orth(u, v):
    return (u @ v) / (v @ v) * v

e = np.ones(n) 

d = D @ e

def orth_obj(z):
    z_o = z - orth(z, d)
    return (z_o @ (D - A) @ z_o)/(z_o @ D @ z_o)
```
```python
import scipy.optimize
z_min = scipy.optimize.minimize(orth_obj,np.random.rand(n)).x
```

## Part E

Recall that, by design, only the sign of `z_min[i]` actually contains information about the cluster label of data point `i`. Plot the original data, using one color for points such that `z_min[i] < 0` and another color for points such that `z_min[i] >= 0`. 


```python

color = (z_min <0)
plt.scatter(X[:,0], X[:,1], c = color)
```
![HW2_5.png](/images/Blog2/HW2_5.png)

## Part F
Recall that what we would like to do is minimize the function:
<math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>R</mi>
    <mi mathvariant="bold">A</mi>
  </msub>
  <mo stretchy="false">(</mo>
  <mi mathvariant="bold">z</mi>
  <mo stretchy="false">)</mo>
  <mo>&#x2261;</mo>
  <mfrac>
    <mrow>
      <msup>
        <mi mathvariant="bold">z</mi>
        <mi>T</mi>
      </msup>
      <mo stretchy="false">(</mo>
      <mi mathvariant="bold">D</mi>
      <mo>&#x2212;</mo>
      <mi mathvariant="bold">A</mi>
      <mo stretchy="false">)</mo>
      <mi mathvariant="bold">z</mi>
    </mrow>
    <mrow>
      <msup>
        <mi mathvariant="bold">z</mi>
        <mi>T</mi>
      </msup>
      <mi mathvariant="bold">D</mi>
      <mi mathvariant="bold">z</mi>
    </mrow>
  </mfrac>
</math>
with respect to  𝐳 , subject to the condition $$ \mathbf{z}^T\mathbf{D}\mathbb{1} = 0 $$

The Rayleigh-Ritz Theorem states that the minimizing  𝐳  must be the solution with smallest eigenvalue of the generalized eigenvalue problem

$$(\mathbf{D} - \mathbf{A}) \mathbf{z} = \lambda \mathbf{D}\mathbf{z}\;, \quad \mathbf{z}^T\mathbf{D}\mathbb{1} = 0$$

which is equivalent to the standard eigenvalue problem

$$\mathbf{D}^{-1}(\mathbf{D} - \mathbf{A}) \mathbf{z} = \lambda \mathbf{z}\;, \quad \mathbf{z}^T\mathbb{1} = 0\;$$

Let' try to define two function: 

1. Laplacian_matrix : Construct the matrix $$\mathbf{L} = \mathbf{D}^{-1}(\mathbf{D} - \mathbf{A})$$

2.z_eig_go: Find the eigenvector corresponding to its second-smallest eigenvalue

                                 

```python
def Laplacian_matrix(A):
    
    D = np.diag(A.sum(axis = 1))
    
    return np.linalg.inv(D) @ (D-A)

L = Laplacian_matrix(A)

def z_eig_go(L):
    eigval, eigvec = np.linalg.eig((L + L.T)/2)
    eigvec = eigvec[:, eigval.argsort()]
    return eigvec[:,1]

z_eig =  z_eig_go(L)
```
```python
plt.scatter(X[:,0], X[:,1], c = np.sign(z_eig))
```
![HW2_6.png](/images/Blog2/HW2_6.png)
{::options parse_block_html="true" /}
<div class="got-help">
My peer inspired me, why not define two functions of Laplacian_matrix and z_eig? We could easily use those two function in our function "spectral_clustering"!
</div>
{::options parse_block_html="false" /}

## Part G

Synthesize your results from the previous parts. In particular, write a function called `spectral_clustering(X, epsilon)` which takes in the input data `X` (in the same format as Part A) and the distance threshold `epsilon` and performs spectral clustering, returning an array of binary labels indicating whether data point `i` is in group `0` or group `1`. Demonstrate your function using the supplied data from the beginning of the problem. 

There is the things our function will need to do:
1. Construct the similarity matrix. 
2. Construct the Laplacian matrix. 
3. Compute the eigenvector with second-smallest eigenvalue of the Laplacian matrix. 
4. Return labels based on this eigenvector. 


```python
def spectral_clustering(X, epsilon):
    '''
    this function computes the label for spectral clustering
    input: array X - the data that we want to perform spectral cluster on
           float epsion - the precision desired
    output: an array indicate the clusters each data point belongs to
    '''
    # use function from PartA construct similar matrix A
    A = similarity_matrix(X,epsilon)
    
    # Use function Laplacian_matrix construct Laplacian matrix
    L = Laplacian_matrix(A)
    
    # Use function z_eig_go get the 2nd smalleset eigenvalue
    z_eig =  z_eig_go(L)
    
    return(1*(z_eig>0))
    
```
```python
spectral_clustering(X, epsilon)
```

```
array([1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1,
       1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0,
       0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0,
       0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0,
       0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,
       0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0,
       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,
       0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0,
       0, 0])
```

```python
plt.scatter(X[:,0], X[:,1], c = spectral_clustering(X, epsilon))
```
![HW2_7.png](/images/Blog2/HW2_7.png)

 
## Part H

```python
X_test, y_test = datasets.make_moons(n_samples=1000, shuffle=True, noise=0.1, random_state=None)
label = spectral_clustering(X_test, epsilon)
plt.scatter(X_test[:,0], X_test[:,1], c = label)
```
![HW2_8.png](/images/Blog2/HW2_8.png)

```python
X_test2, y_test2 = datasets.make_moons(n_samples=1000, shuffle=True, noise=0.2, random_state=None)
label = spectral_clustering(X_test2, epsilon)
plt.scatter(X_test2[:,0], X_test2[:,1], c = label)
```
![HW2_9.png](/images/Blog2/HW2_9.png)

## Part I
Now try your spectral clustering function on another data set -- the bull's eye!

```python
n = 1000
X, y = datasets.make_circles(n_samples=n, shuffle=True, noise=0.05, random_state=None, factor = 0.4)
plt.scatter(X[:,0], X[:,1])
```
![HW2_10.png](/images/Blog2/HW2_10.png)
There are two concentric circles. As before k-means will not do well here at all.
```python
km = KMeans(n_clusters = 2)
km.fit(X)
plt.scatter(X[:,0], X[:,1], c = km.predict(X))
```
![HW2_11.png](/images/Blog2/HW2_11.png)

Let's define a function to testing our epsilon

```python

def plot_spectral(X,epsilon):
    label = spectral_clustering(X, epsilon)
    plt.scatter(X[:,0], X[:,1], c = label)

```
Let's try epsilon = 0.1!
```python
plot_spectral(X,0.1)
```
```python
---------------------------------------------------------------------------
LinAlgError                               Traceback (most recent call last)
<ipython-input-41-aaa822c0c6c5> in <module>
----> 1 plot_spectral(X,0.1)

<ipython-input-29-7b2b684770ee> in plot_spectral(X, epsilon)
      1 def plot_spectral(X,epsilon):
----> 2     label = spectral_clustering(X, epsilon)
      3     plt.scatter(X[:,0], X[:,1], c = label)

<ipython-input-22-31bede5151e0> in spectral_clustering(X, epsilon)
     13     # Laplacian matrix
     14     D = np.diag(A.sum(axis = 1))
---> 15     L = np.linalg.inv(D)@(D-A)
     16 
     17     # 2nd smalleset eigenvalue

<__array_function__ internals> in inv(*args, **kwargs)

~\anaconda3\lib\site-packages\numpy\linalg\linalg.py in inv(a)
    544     signature = 'D->D' if isComplexType(t) else 'd->d'
    545     extobj = get_linalg_error_extobj(_raise_linalgerror_singular)
--> 546     ainv = _umath_linalg.inv(a, signature=signature, extobj=extobj)
    547     return wrap(ainv.astype(result_t, copy=False))
    548 

~\anaconda3\lib\site-packages\numpy\linalg\linalg.py in _raise_linalgerror_singular(err, flag)
     86 
     87 def _raise_linalgerror_singular(err, flag):
---> 88     raise LinAlgError("Singular matrix")
     89 
     90 def _raise_linalgerror_nonposdef(err, flag):

LinAlgError: Singular matrix
```
Error message come out. Looks like epsilon = 0.1 makes our D to a Singular matrix. So we can't take inverse of D. 
It's OK Let's try epsilon = 0.2


```python
plot_spectral(X,0.2)
```

![HW2_7.png](/images/Blog2/HW2_11.png)

Ummm looks like it doing not well with epsilon = 0.2
Let's try epsilon = 0.3
```python
plot_spectral(X,0.3)
```

![HW2_7.png](/images/Blog2/HW2_12.png)
Great! It works with epsilon = 0.3

```python
plot_spectral(X,0.4)
```

![HW2_7.png](/images/Blog2/HW2_12.png)

Great! It also works with epsilon = 0.4
```python
plot_spectral(X,0.5)
```

![HW2_7.png](/images/Blog2/HW2_14.png)

Great! It alsoworks with epsilon = 0.5

```python
plot_spectral(X,0.6)
```
![HW2_7.png](/images/Blog2/HW2_13.png)

Based on our test our we are correctly separate the two rings with values of epsilon between 0.3-0.5!!!